{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# -*- authors : Vincent Roduit -*-\n",
    "# -*- date : 2025-04-24 -*-\n",
    "# -*- Last revision: 2025-05-02 by janzgraggen -*-\n",
    "# -*- python version : 3.10.4 -*-\n",
    "# -*- Description: Notebook that summarizeses the main results-*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> EE-452: Network Machine Learning </center>\n",
    "## <center> Ecole Polytechnique Fédérale de Lausanne </center>\n",
    "### <center>Graph-based EEG Analysis </center>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from seiz_eeg.dataset import EEGDataset\n",
    "\n",
    "#import modules\n",
    "import constants\n",
    "from transform_func import *\n",
    "from dataloader import load_data\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "\n",
    "DATA_ROOT = Path(data_path)\n",
    "\n",
    "clips_tr = pd.read_parquet(DATA_ROOT / \"train/segments.parquet\")\n",
    "\n",
    "# You can change the signal_transform, or remove it completely\n",
    "dataset_tr = EEGDataset(\n",
    "    clips_tr,\n",
    "    signals_root=DATA_ROOT / \"train\",\n",
    "    signal_transform=None,\n",
    "    prefetch=True,  # If your compute does not allow it, you can use `prefetch=False`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "# Configuration\n",
    "FS = 250                # Sampling frequency\n",
    "WIN_SEC = 2.0           # Window length in seconds\n",
    "OVERLAP = 0.5           # 50% overlap\n",
    "WAVELET = 'db4'         # Mother wavelet\n",
    "DWT_LEVEL = 5           # A5, D5, D4, D3, D2 → 5 bands\n",
    "EPS = 1e-6              # Small value to avoid division by zero\n",
    "def safe_corrcoef(data):\n",
    "    std = np.std(data, axis=1, keepdims=True)\n",
    "    std[std == 0] = 1e-10  # avoid division by zero\n",
    "    normed = (data - data.mean(axis=1, keepdims=True)) / std\n",
    "    return np.dot(normed, normed.T) / data.shape[1]\n",
    "\n",
    "# 1. Sliding windows\n",
    "def sliding_windows(arr, win_len, step):\n",
    "    n_ch, n_total = arr.shape\n",
    "    for start in range(0, n_total - win_len + 1, step):\n",
    "        yield arr[:, start:start + win_len]\n",
    "\n",
    "# 2. Band-wise statistics\n",
    "def features_one_channel(sig, fs=FS, wavelet=WAVELET, level=DWT_LEVEL):\n",
    "    # Time-domain\n",
    "    xavg = np.mean(sig)\n",
    "    xarv = np.mean(np.abs(sig))\n",
    "    xstd = np.std(sig)\n",
    "    xp2p = np.ptp(sig)\n",
    "    xcross = np.sum(sig[:-1] * sig[1:] < 0) / len(sig)\n",
    "    F_time = [xavg, xarv, xstd, xp2p, xcross]\n",
    "\n",
    "    # FFT → PSD\n",
    "    fft = np.fft.rfft(sig)\n",
    "    freqs = np.fft.rfftfreq(len(sig), d=1/fs)\n",
    "    psd = (np.abs(fft) ** 2) / len(sig)\n",
    "\n",
    "    # Truncate both to 128 points\n",
    "    psd = psd[:128]\n",
    "    freqs = freqs[:128]\n",
    "    band_limits = [(0.5,4), (4,7), (7,15), (15,31), (31,fs//2)]\n",
    "    F_psdband = [np.mean(psd[(freqs >= fmin) & (freqs < fmax)]) for fmin, fmax in band_limits]\n",
    "\n",
    "    # CWT\n",
    "    scales = np.arange(2, 129)\n",
    "    cwtmat, _ = pywt.cwt(sig, scales, 'morl')  # use 'morl' for continuous wavelet\n",
    "    energy = np.sum(np.abs(cwtmat) ** 2, axis=1)\n",
    "    F_cwt = energy\n",
    "    F_cwtband = []\n",
    "    F_psd = psd\n",
    "    for fmin, fmax in band_limits:\n",
    "        idx = (fs * 0.8125 / scales >= fmin) & (fs * 0.8125 / scales < fmax)\n",
    "        F_cwtband.append(np.mean(energy[idx]) if np.any(idx) else 0)\n",
    "\n",
    "    return np.concatenate([F_time, F_psd, F_psdband, F_cwt, F_cwtband])  # 5 + 128 + 5 + 127 + 5 = 270\n",
    "\n",
    "# 3. Window features\n",
    "def features_one_window(win):\n",
    "    return np.stack([features_one_channel(ch) for ch in win], axis=0)  # (channels, 270)\n",
    "\n",
    "# 4. Pearson edge construction (from full signal or window)\n",
    "def compute_edge_index(data, threshold=0.8):\n",
    "    C = data.shape[0]\n",
    "    corr = safe_corrcoef(data)\n",
    "    edge_index = []\n",
    "\n",
    "    for i in range(C):\n",
    "        for j in range(C):\n",
    "            if i != j and abs(corr[i, j]) >= threshold:\n",
    "                edge_index.append([i, j])\n",
    "\n",
    "    # Add self-loops\n",
    "    edge_index += [[i, i] for i in range(C)]\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()  # shape: [2, num_edges]\n",
    "    return edge_index\n",
    "\n",
    "# 5. Full pipeline: (19, 3000) → list of torch_geometric Data objects (11 windows)\n",
    "def extract_graph_sequence(data):\n",
    "    win_len = int(WIN_SEC * FS)      # 500\n",
    "    step    = int(win_len * (1 - OVERLAP))  # 250\n",
    "\n",
    "    # Static edge index for the whole signal\n",
    "    edge_index = compute_edge_index(data)\n",
    "\n",
    "    graph_list = []\n",
    "    for win in sliding_windows(data, win_len, step):\n",
    "        x = features_one_window(win)  # (19, 270)\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        graph = Data(x=x, edge_index=edge_index)\n",
    "        graph_list.append(graph)\n",
    "\n",
    "    return graph_list  # len = num timesteps (e.g., 11), each item is a Data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 timesteps, shape of x: torch.Size([19, 270])\n"
     ]
    }
   ],
   "source": [
    "data = dataset_tr[0][0].T\n",
    "\n",
    "graph_sequence = extract_graph_sequence(data)\n",
    "print(f\"{len(graph_sequence)} timesteps, shape of x: {graph_sequence[0].x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[19, 270], edge_index=[2, 49]),\n",
       " Data(x=[19, 270], edge_index=[2, 49]),\n",
       " Data(x=[19, 270], edge_index=[2, 49]),\n",
       " Data(x=[19, 270], edge_index=[2, 49]),\n",
       " Data(x=[19, 270], edge_index=[2, 49]),\n",
       " Data(x=[19, 270], edge_index=[2, 49]),\n",
       " Data(x=[19, 270], edge_index=[2, 49]),\n",
       " Data(x=[19, 270], edge_index=[2, 49]),\n",
       " Data(x=[19, 270], edge_index=[2, 49]),\n",
       " Data(x=[19, 270], edge_index=[2, 49]),\n",
       " Data(x=[19, 270], edge_index=[2, 49])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sequence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
